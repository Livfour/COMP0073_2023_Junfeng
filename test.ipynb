{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets.posetrack21 import PoseTrack21\n",
    "from utilities.utilities import keypoints_to_mask, accuracy, show_image, HiddenPrints, show_heatmaps, keypoints_to_label_flag\n",
    "from mmpose.evaluation import pose_pck_accuracy, keypoint_pck_accuracy\n",
    "from mmpose.codecs import UDPHeatmap\n",
    "from models.backbone.vit_with_fusion import FusionVit\n",
    "from models.head.deconv import DeconvHead\n",
    "from models.PoseEstimate import PoseEstimate\n",
    "from models.head import MaskHead, ResMaskHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ./checkpoints/Fusion_Mask_01.pth at epoch 2200\n"
     ]
    }
   ],
   "source": [
    "# device = \"cpu\"\n",
    "device = \"cuda\"\n",
    "pretrained_path = \"./checkpoints/vitpose_base_coco_aic_mpii.pth\"\n",
    "encoder = FusionVit(pretrained_path=pretrained_path)\n",
    "neck = nn.Identity()\n",
    "head = MaskHead(pretrained_path=pretrained_path)\n",
    "model = PoseEstimate(encoder=encoder, neck=neck, head=head)\n",
    "model.to(device)\n",
    "model_path = \"./checkpoints/Fusion_Mask_01.pth\"\n",
    "model_dict = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(model_dict[\"model_state_dict\"])\n",
    "epoch = model_dict[\"epoch\"]\n",
    "print(f\"Loaded model from {model_path} at epoch {epoch}\")\n",
    "with HiddenPrints():\n",
    "    model.to(device)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_heatmaps(heatmaps):\n",
    "    \"\"\"\n",
    "    Normalizes heatmaps to the range [0, 1].\n",
    "\n",
    "    Parameters:\n",
    "    - heatmaps: torch.Tensor of shape (num_joints, height, width)\n",
    "                17 * 64 * 48 in your case.\n",
    "\n",
    "    Returns:\n",
    "    - normalized_heatmaps: torch.Tensor of shape (num_joints, height, width)\n",
    "    \"\"\"\n",
    "    num_joints, height, width = heatmaps.shape\n",
    "    normalized_heatmaps = torch.zeros_like(heatmaps, dtype=torch.float32)\n",
    "\n",
    "    for i in range(num_joints):\n",
    "        min_val = torch.min(heatmaps[i])\n",
    "        max_val = torch.max(heatmaps[i])\n",
    "\n",
    "        if max_val != min_val:\n",
    "            normalized_heatmaps[i] = (heatmaps[i] - min_val) / (max_val - min_val)\n",
    "\n",
    "    return normalized_heatmaps\n",
    "\n",
    "# Example usage\n",
    "heatmaps = torch.rand(17, 64, 48)  # Generating random heatmaps for 17 joints, 64x48 in size.\n",
    "normalized_heatmaps = normalize_heatmaps(heatmaps)\n",
    "\n",
    "# Now `normalized_heatmaps` contains the normalized values in the range [0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "dataset_root_dir = \"/home/junfeng/datasets/PoseTrack21\"\n",
    "dataset_train = PoseTrack21(\n",
    "    root_dir=dataset_root_dir,\n",
    "    set=\"train\",\n",
    ")\n",
    "\n",
    "dataset_test = PoseTrack21(\n",
    "    root_dir=dataset_root_dir,\n",
    "    set=\"test\",\n",
    ")\n",
    "\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7856290875790942, mean_avg_acc 0.7724390664890722\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7945764646464689, mean_avg_acc 0.7815957337107394\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed, 4)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7948723848373896, mean_avg_acc 0.7836220823620867\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed, 8)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7874665306915355, mean_avg_acc 0.7694805106005154\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed, 4)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7746848268398318, mean_avg_acc 0.7590067671217716\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 100)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7809621439671497, mean_avg_acc 0.7679355422355479\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 100)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 404, mean_avg_acc_udp: 0.7780919506785843, mean_avg_acc 0.7601746438380105\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m heatmaps \u001b[39m=\u001b[39m heatmaps\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     17\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 18\u001b[0m     pred_heatmaps \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(video_transformed)\n\u001b[1;32m     19\u001b[0m     pred_heatmaps \u001b[39m=\u001b[39m normalize_heatmaps(pred_heatmaps\u001b[39m.\u001b[39msqueeze())\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m     pred_heatmaps \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdenoise(video_transformed, pred_heatmaps, \u001b[39m200\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/WorkSpace/SummerProject/COMP0073_2023_Junfeng/models/PoseEstimate.py:35\u001b[0m, in \u001b[0;36mPoseEstimate.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[1;32m     34\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneck(x)\n\u001b[0;32m---> 35\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhead\u001b[39m.\u001b[39;49mpredict(x)\n\u001b[1;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/WorkSpace/SummerProject/COMP0073_2023_Junfeng/models/head/ResMaskHead.py:164\u001b[0m, in \u001b[0;36mResMaskHead.predict\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39mf: (B, embed_dim, num_patches_height, num_patches_width)\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m B \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 164\u001b[0m h \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrandn(B, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_keypoints, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mH_heatmap, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW_heatmap)\u001b[39m.\u001b[39;49mto(\n\u001b[1;32m    165\u001b[0m     f\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    166\u001b[0m _ts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    167\u001b[0m                    device\u001b[39m=\u001b[39mf\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mrepeat(B, \u001b[39m1\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(f, h, _ts)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 200)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7843654512154561, mean_avg_acc 0.7692100610500648\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 100)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 100)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 200)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.7078595186969576, mean_avg_acc 0.6801411027396254\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed, 4)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.6984643161983062, mean_avg_acc 0.6747006448669019\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 0)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.7026575299358544, mean_avg_acc 0.6792526063154142\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 10)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.700220718662837, mean_avg_acc 0.67802453430532281\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.7066986892417929, mean_avg_acc 0.6791074073709547\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 200)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.7068403920928551, mean_avg_acc 0.6816651123917139\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model(video_transformed, pred_heatmaps)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "acc = 0\n",
    "count = 0\n",
    "i = np.random.randint(0, len(dataset))\n",
    "video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "image = video[1]\n",
    "H, W, _ = image.shape\n",
    "decoder = UDPHeatmap(input_size=(W, H), heatmap_size=(48, 64))\n",
    "image_transformed = video_transformed[1]\n",
    "video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "show_image(image, keypoints)\n",
    "with torch.no_grad():\n",
    "    pred_heatmaps = model.predict(video_transformed)\n",
    "    show_image(image, heatmaps=pred_heatmaps.squeeze(0).cpu().numpy())\n",
    "    show_heatmaps(pred_heatmaps.squeeze(0).cpu().numpy())\n",
    "    pred_heatmaps = model.denoise(video_transformed, pred_heatmaps)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt21_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
