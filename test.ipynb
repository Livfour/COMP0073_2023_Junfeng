{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets.posetrack21 import PoseTrack21\n",
    "from utilities.utilities import keypoints_to_mask, accuracy, show_image, HiddenPrints, show_heatmaps, keypoints_to_label_flag\n",
    "from mmpose.evaluation import pose_pck_accuracy, keypoint_pck_accuracy\n",
    "from mmpose.codecs import UDPHeatmap\n",
    "from models.backbone.vit_with_fusion import FusionVit\n",
    "from models.head.deconv import DeconvHead\n",
    "from models.PoseEstimate import PoseEstimate\n",
    "from models.head import MaskHead, ResMaskHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ./checkpoints/Fusion_Mask_01.pth at epoch 2200\n"
     ]
    }
   ],
   "source": [
    "# device = \"cpu\"\n",
    "device = \"cuda\"\n",
    "pretrained_path = \"./checkpoints/vitpose_base_coco_aic_mpii.pth\"\n",
    "encoder = FusionVit(pretrained_path=pretrained_path)\n",
    "neck = nn.Identity()\n",
    "head = MaskHead(pretrained_path=pretrained_path)\n",
    "model = PoseEstimate(encoder=encoder, neck=neck, head=head)\n",
    "model.to(device)\n",
    "model_path = \"./checkpoints/Fusion_Mask_01.pth\"\n",
    "model_dict = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(model_dict[\"model_state_dict\"])\n",
    "epoch = model_dict[\"epoch\"]\n",
    "print(f\"Loaded model from {model_path} at epoch {epoch}\")\n",
    "with HiddenPrints():\n",
    "    model.to(device)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_heatmaps(heatmaps):\n",
    "    \"\"\"\n",
    "    Normalizes heatmaps to the range [0, 1].\n",
    "\n",
    "    Parameters:\n",
    "    - heatmaps: torch.Tensor of shape (num_joints, height, width)\n",
    "                17 * 64 * 48 in your case.\n",
    "\n",
    "    Returns:\n",
    "    - normalized_heatmaps: torch.Tensor of shape (num_joints, height, width)\n",
    "    \"\"\"\n",
    "    num_joints, height, width = heatmaps.shape\n",
    "    normalized_heatmaps = torch.zeros_like(heatmaps, dtype=torch.float32)\n",
    "\n",
    "    for i in range(num_joints):\n",
    "        min_val = torch.min(heatmaps[i])\n",
    "        max_val = torch.max(heatmaps[i])\n",
    "\n",
    "        if max_val != min_val:\n",
    "            normalized_heatmaps[i] = (heatmaps[i] - min_val) / (max_val - min_val)\n",
    "\n",
    "    return normalized_heatmaps\n",
    "\n",
    "# Example usage\n",
    "heatmaps = torch.rand(17, 64, 48)  # Generating random heatmaps for 17 joints, 64x48 in size.\n",
    "normalized_heatmaps = normalize_heatmaps(heatmaps)\n",
    "\n",
    "# Now `normalized_heatmaps` contains the normalized values in the range [0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "dataset_root_dir = \"/home/junfeng/datasets/PoseTrack21\"\n",
    "dataset_train = PoseTrack21(\n",
    "    root_dir=dataset_root_dir,\n",
    "    set=\"train\",\n",
    ")\n",
    "\n",
    "dataset_test = PoseTrack21(\n",
    "    root_dir=dataset_root_dir,\n",
    "    set=\"test\",\n",
    ")\n",
    "\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def toP(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def get_mean_average_acc(TP, P):\n",
    "    return sum(TP) / sum(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 999, mean_avg_acc: 0.7740311133311121, mean_avg_acc_batch: 0.7740311133311121, mean_avg_acc_TP: 0.8079043161726469\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc = 0\n",
    "mean_avg_acc_batch = 0\n",
    "TP = [0]*17\n",
    "P = [0]*17\n",
    "count = 0\n",
    "thr = 0.05\n",
    "batch_size = 1\n",
    "\n",
    "# collate\n",
    "for i in range(1000):\n",
    "    mask_list = []\n",
    "    heatmaps_list = []\n",
    "    pred_heatmaps_list = []\n",
    "    for j in range(batch_size):\n",
    "        video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[np.random.randint(\n",
    "            0, len(dataset))]\n",
    "        heatmaps = heatmaps.unsqueeze(0).numpy()\n",
    "        mask = keypoints_to_mask(keypoints)\n",
    "        with torch.no_grad():\n",
    "            video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "            pred_heatmaps = model.predict(video_transformed)\n",
    "            pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "            acc, avg_acc, _ = pose_pck_accuracy(\n",
    "                pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "            mean_avg_acc += avg_acc\n",
    "            count += 1\n",
    "            P = [P[k] + toP(acc[k]) for k in range(len(acc))]\n",
    "            TP = [TP[k] + ReLu(acc[k]) for k in range(len(acc))]\n",
    "            mask_list.append(np.squeeze(mask))\n",
    "            heatmaps_list.append(np.squeeze(heatmaps))\n",
    "            pred_heatmaps_list.append(np.squeeze(pred_heatmaps))\n",
    "    mask_list = np.array(mask_list)\n",
    "    heatmaps_list = np.array(heatmaps_list)\n",
    "    pred_heatmaps_list = np.array(pred_heatmaps_list)\n",
    "    _, avg_acc_batch, _ = pose_pck_accuracy(\n",
    "        pred_heatmaps_list, heatmaps_list, mask_list, thr=thr)\n",
    "    mean_avg_acc_batch += avg_acc_batch\n",
    "    print(f\"i: {i}, mean_avg_acc: {mean_avg_acc / count}, mean_avg_acc_batch: {mean_avg_acc_batch / (i+1)}, mean_avg_acc_TP: {get_mean_average_acc(TP, P)}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "i: 0, mean_avg_acc: 0.6273809523809524, mean_avg_acc_batch: 0.5833333333333333, mean_avg_acc_TP: 0.6060606060606061\n",
      "weighted_average: 0.6060606060606061\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc = 0\n",
    "mean_avg_acc_batch = 0\n",
    "avg_acc_list = []\n",
    "weight_list = []\n",
    "TP = [0]*17\n",
    "P = [0]*17\n",
    "count = 0\n",
    "thr = 0.05\n",
    "batch_size = 4\n",
    "\n",
    "# collate\n",
    "for i in range(1):\n",
    "    mask_list = []\n",
    "    heatmaps_list = []\n",
    "    pred_heatmaps_list = []\n",
    "    for j in range(batch_size):\n",
    "        video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[np.random.randint(\n",
    "            0, len(dataset))]\n",
    "        heatmaps = heatmaps.unsqueeze(0).numpy()\n",
    "        mask = keypoints_to_mask(keypoints)\n",
    "        with torch.no_grad():\n",
    "            video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "            pred_heatmaps = model.predict(video_transformed)\n",
    "            pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "            acc, avg_acc, cnt = pose_pck_accuracy(\n",
    "                pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "            mean_avg_acc += avg_acc\n",
    "            avg_acc_list.append(avg_acc)\n",
    "            weight_list.append(cnt)\n",
    "            count += 1\n",
    "            P = [P[k] + toP(acc[k]) for k in range(len(acc))]\n",
    "            TP = [TP[k] + ReLu(acc[k]) for k in range(len(acc))]\n",
    "            mask_list.append(np.squeeze(mask))\n",
    "            heatmaps_list.append(np.squeeze(heatmaps))\n",
    "            pred_heatmaps_list.append(np.squeeze(pred_heatmaps))\n",
    "    mask_list = np.array(mask_list)\n",
    "    heatmaps_list = np.array(heatmaps_list)\n",
    "    pred_heatmaps_list = np.array(pred_heatmaps_list)\n",
    "    _, avg_acc_batch, cnt_batch = pose_pck_accuracy(\n",
    "        pred_heatmaps_list, heatmaps_list, mask_list, thr=thr)\n",
    "    print(cnt_batch)\n",
    "    mean_avg_acc_batch += avg_acc_batch\n",
    "    print(f\"i: {i}, mean_avg_acc: {mean_avg_acc / count}, mean_avg_acc_batch: {mean_avg_acc_batch / (i+1)}, mean_avg_acc_TP: {get_mean_average_acc(TP, P)}\")\n",
    "    print(f\"weighted_average: {weighted_average(avg_acc_list, weight_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 999, mean_avg_acc: 0.7520228049728039, mean_avg_acc_batch: 0.7520228049728039, mean_avg_acc_TP: 0.7836779848523533\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc = 0\n",
    "mean_avg_acc_batch = 0\n",
    "TP = [0]*17\n",
    "P = [0]*17\n",
    "count = 0\n",
    "thr = 0.05\n",
    "batch_size = 1\n",
    "\n",
    "# collate\n",
    "for i in range(1000):\n",
    "    mask_list = []\n",
    "    heatmaps_list = []\n",
    "    pred_heatmaps_list = []\n",
    "    for j in range(batch_size):\n",
    "        video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[np.random.randint(\n",
    "            0, len(dataset))]\n",
    "        heatmaps = heatmaps.unsqueeze(0).numpy()\n",
    "        mask = keypoints_to_mask(keypoints)\n",
    "        with torch.no_grad():\n",
    "            video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "            pred_heatmaps = model.predict(video_transformed)\n",
    "            pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "            acc, avg_acc, _ = accuracy(\n",
    "                pred_heatmaps, heatmaps)\n",
    "            acc = acc[1:]\n",
    "            mean_avg_acc += avg_acc\n",
    "            count += 1\n",
    "            P = [P[k] + toP(acc[k]) for k in range(len(acc))]\n",
    "            TP = [TP[k] + ReLu(acc[k]) for k in range(len(acc))]\n",
    "            mask_list.append(np.squeeze(mask))\n",
    "            heatmaps_list.append(np.squeeze(heatmaps))\n",
    "            pred_heatmaps_list.append(np.squeeze(pred_heatmaps))\n",
    "    mask_list = np.array(mask_list)\n",
    "    heatmaps_list = np.array(heatmaps_list)\n",
    "    pred_heatmaps_list = np.array(pred_heatmaps_list)\n",
    "    _, avg_acc_batch, _ = accuracy(\n",
    "        pred_heatmaps_list, heatmaps_list)\n",
    "    mean_avg_acc_batch += avg_acc_batch\n",
    "    print(f\"i: {i}, mean_avg_acc: {mean_avg_acc / count}, mean_avg_acc_batch: {mean_avg_acc_batch / (i+1)}, mean_avg_acc_TP: {get_mean_average_acc(TP, P)}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 133, mean_avg_acc: 0.7356420113882794, mean_avg_acc_batch: 0.7588472472800833, mean_avg_acc_TP: 0.7632627051139079\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     22\u001b[0m     video_transformed \u001b[39m=\u001b[39m video_transformed\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m     pred_heatmaps \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(video_transformed)\n\u001b[1;32m     24\u001b[0m     pred_heatmaps \u001b[39m=\u001b[39m pred_heatmaps\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     25\u001b[0m     acc, avg_acc, _ \u001b[39m=\u001b[39m accuracy(\n\u001b[1;32m     26\u001b[0m         pred_heatmaps, heatmaps)\n",
      "File \u001b[0;32m~/Documents/WorkSpace/SummerProject/COMP0073_2023_Junfeng/models/PoseEstimate.py:43\u001b[0m, in \u001b[0;36mPoseEstimate.predict_diffusion\u001b[0;34m(self, x, n)\u001b[0m\n\u001b[1;32m     41\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[1;32m     42\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneck(x)\n\u001b[0;32m---> 43\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhead\u001b[39m.\u001b[39;49mpredict(x, n\u001b[39m=\u001b[39;49mn)\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/WorkSpace/SummerProject/COMP0073_2023_Junfeng/models/head/MaskHead.py:115\u001b[0m, in \u001b[0;36mMaskHead.predict\u001b[0;34m(self, f, n)\u001b[0m\n\u001b[1;32m    113\u001b[0m B \u001b[39m=\u001b[39m n\n\u001b[1;32m    114\u001b[0m f \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mrepeat(B, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m h \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrandn(B, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_keypoints, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mH_heatmap, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW_heatmap)\u001b[39m.\u001b[39;49mto(\n\u001b[1;32m    116\u001b[0m     f\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    117\u001b[0m _ts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    118\u001b[0m                    device\u001b[39m=\u001b[39mf\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mrepeat(B, \u001b[39m1\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mmean(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(f, h, _ts), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc = 0\n",
    "mean_avg_acc_batch = 0\n",
    "TP = [0]*17\n",
    "P = [0]*17\n",
    "count = 0\n",
    "thr = 0.05\n",
    "batch_size = 4\n",
    "\n",
    "# collate\n",
    "for i in range(1000):\n",
    "    mask_list = []\n",
    "    heatmaps_list = []\n",
    "    pred_heatmaps_list = []\n",
    "    for j in range(batch_size):\n",
    "        video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[np.random.randint(\n",
    "            0, len(dataset))]\n",
    "        heatmaps = heatmaps.unsqueeze(0).numpy()\n",
    "        mask = keypoints_to_mask(keypoints)\n",
    "        with torch.no_grad():\n",
    "            video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "            pred_heatmaps = model.predict(video_transformed)\n",
    "            pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "            acc, avg_acc, _ = accuracy(\n",
    "                pred_heatmaps, heatmaps)\n",
    "            acc = acc[1:]\n",
    "            mean_avg_acc += avg_acc\n",
    "            count += 1\n",
    "            P = [P[k] + toP(acc[k]) for k in range(len(acc))]\n",
    "            TP = [TP[k] + ReLu(acc[k]) for k in range(len(acc))]\n",
    "            mask_list.append(np.squeeze(mask))\n",
    "            heatmaps_list.append(np.squeeze(heatmaps))\n",
    "            pred_heatmaps_list.append(np.squeeze(pred_heatmaps))\n",
    "    mask_list = np.array(mask_list)\n",
    "    heatmaps_list = np.array(heatmaps_list)\n",
    "    pred_heatmaps_list = np.array(pred_heatmaps_list)\n",
    "    _, avg_acc_batch, _ = accuracy(\n",
    "        pred_heatmaps_list, heatmaps_list)\n",
    "    mean_avg_acc_batch += avg_acc_batch\n",
    "    print(f\"i: {i}, mean_avg_acc: {mean_avg_acc / count}, mean_avg_acc_batch: {mean_avg_acc_batch / (i+1)}, mean_avg_acc_TP: {get_mean_average_acc(TP, P)}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, 0.819195909830351 0.8326748779920985,,\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc = 0\n",
    "mean_avg_acc_udp = 0\n",
    "TP = [0]*17\n",
    "P = [0]*17\n",
    "mean_acc = [0]*17\n",
    "mean_acc_upd = [0]*17\n",
    "TP_udp = [0]*17\n",
    "P_udp = [0]*17\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        acc, avg_acc, cnt = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        P = [P[i] + toP(acc[i]) for i in range(len(acc))]\n",
    "        TP = [TP[i] + ReLu(acc[i]) for i in range(len(acc))]\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        acc_udp, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        P_udp = [P_udp[i] + toP(acc_udp[i]) for i in range(len(acc_udp))]\n",
    "        TP_udp = [TP_udp[i] + ReLu(acc_udp[i]) for i in range(len(acc_udp))]\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, {get_mean_average_acc(TP, P)} {get_mean_average_acc(TP_udp, P_udp)},\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7861711288711349, mean_avg_acc 0.7727698174048236\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7900421972472023, mean_avg_acc 0.7788762742812795\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed, 4)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7856290875790942, mean_avg_acc 0.7724390664890722\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7945764646464689, mean_avg_acc 0.7815957337107394\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed, 4)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7948723848373896, mean_avg_acc 0.7836220823620867\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed, 8)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7874665306915355, mean_avg_acc 0.7694805106005154\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed, 4)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7746848268398318, mean_avg_acc 0.7590067671217716\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 100)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7809621439671497, mean_avg_acc 0.7679355422355479\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 100)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 404, mean_avg_acc_udp: 0.7780919506785843, mean_avg_acc 0.7601746438380105\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m heatmaps \u001b[39m=\u001b[39m heatmaps\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     17\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 18\u001b[0m     pred_heatmaps \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(video_transformed)\n\u001b[1;32m     19\u001b[0m     pred_heatmaps \u001b[39m=\u001b[39m normalize_heatmaps(pred_heatmaps\u001b[39m.\u001b[39msqueeze())\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m     pred_heatmaps \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdenoise(video_transformed, pred_heatmaps, \u001b[39m200\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/WorkSpace/SummerProject/COMP0073_2023_Junfeng/models/PoseEstimate.py:35\u001b[0m, in \u001b[0;36mPoseEstimate.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[1;32m     34\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneck(x)\n\u001b[0;32m---> 35\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhead\u001b[39m.\u001b[39;49mpredict(x)\n\u001b[1;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/WorkSpace/SummerProject/COMP0073_2023_Junfeng/models/head/ResMaskHead.py:164\u001b[0m, in \u001b[0;36mResMaskHead.predict\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39mf: (B, embed_dim, num_patches_height, num_patches_width)\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m B \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 164\u001b[0m h \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrandn(B, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_keypoints, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mH_heatmap, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW_heatmap)\u001b[39m.\u001b[39;49mto(\n\u001b[1;32m    165\u001b[0m     f\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    166\u001b[0m _ts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    167\u001b[0m                    device\u001b[39m=\u001b[39mf\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mrepeat(B, \u001b[39m1\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(f, h, _ts)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 200)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7843654512154561, mean_avg_acc 0.7692100610500648\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 100)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 100)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 200)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.706771953416042, mean_avg_acc 0.68863766911796455\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.7099827444039263, mean_avg_acc 0.6916903430450231\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed, 4)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.7125605613598219, mean_avg_acc 0.6940600723851956\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.unsqueeze(0).cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed, 4)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 4, 200)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.7026575299358544, mean_avg_acc 0.6792526063154142\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 10)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.700220718662837, mean_avg_acc 0.67802453430532281\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.7066986892417929, mean_avg_acc 0.6791074073709547\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 200)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 812, mean_avg_acc_udp: 0.7068403920928551, mean_avg_acc 0.6816651123917139\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model(video_transformed, pred_heatmaps)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "acc = 0\n",
    "count = 0\n",
    "i = np.random.randint(0, len(dataset))\n",
    "video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "image = video[1]\n",
    "H, W, _ = image.shape\n",
    "decoder = UDPHeatmap(input_size=(W, H), heatmap_size=(48, 64))\n",
    "image_transformed = video_transformed[1]\n",
    "video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "show_image(image, keypoints)\n",
    "with torch.no_grad():\n",
    "    pred_heatmaps = model.predict(video_transformed, 8)\n",
    "    show_image(image, heatmaps=pred_heatmaps.squeeze(0).cpu().numpy())\n",
    "    show_heatmaps(pred_heatmaps.squeeze(0).cpu().numpy())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt21_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
