{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/junfeng/Documents/WorkSpace/SummerProject/COMP0073_2023_Junfeng\n"
     ]
    }
   ],
   "source": [
    "%cd /home/junfeng/Documents/WorkSpace/SummerProject/COMP0073_2023_Junfeng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "\n",
    "from datasets.posetrack21 import PoseTrack21\n",
    "from utilities.utilities import keypoints_to_mask, HiddenPrints, normalize_heatmaps, ReLu, count_positive, get_mean_average_acc\n",
    "from mmpose.evaluation import pose_pck_accuracy, keypoint_pck_accuracy\n",
    "from mmpose.codecs import UDPHeatmap\n",
    "\n",
    "from models.PoseEstimate import PoseEstimate\n",
    "from models.backbone import ResNet50, ViTEncoder, VideoViTEncoder, FusionVit\n",
    "from models.neck import UnPatch\n",
    "from models.head import DeconvHead, MaskHead, ResMaskHead, SimpleHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "dataset_root_dir = \"/home/junfeng/datasets/PoseTrack21\"\n",
    "dataset_train = PoseTrack21(\n",
    "    root_dir=dataset_root_dir,\n",
    "    set=\"train\",\n",
    ")\n",
    "\n",
    "dataset_test = PoseTrack21(\n",
    "    root_dir=dataset_root_dir,\n",
    "    set=\"test\",\n",
    ")\n",
    "\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ./checkpoints/Fusion_Deconv_Best_02.pth at epoch 1600\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pretrained_path = \"./checkpoints/vitpose_base_coco_aic_mpii.pth\"\n",
    "encoder = ViTEncoder(pretrained_path=pretrained_path)\n",
    "neck = nn.UnPatch()\n",
    "head = DeconvHead(pretrained_path=pretrained_path)\n",
    "model = PoseEstimate(encoder=encoder, neck=neck, head=head)\n",
    "model_path = \"./checkpoints/Single_Frame_ViT_Deconv_01.pth\"\n",
    "# model_dict = torch.load(model_path, map_location=device)\n",
    "# model.load_state_dict(model_dict[\"model_state_dict\"])\n",
    "# epoch = model_dict[\"epoch\"]\n",
    "# print(f\"Loaded model from {model_path} at epoch {epoch}\")\n",
    "with HiddenPrints():\n",
    "    model.to(device)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video: 169 / 170\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "TP = [0]*17\n",
    "P = [0]*17\n",
    "TP_udp = [0]*17\n",
    "P_udp = [0]*17\n",
    "udp = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "thr = 0.05\n",
    "with torch.no_grad():\n",
    "    for i in range(len(dataset)):\n",
    "        for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(i):\n",
    "            mask = keypoints_to_mask(keypoints)\n",
    "            video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "            heatmaps = heatmaps.unsqueeze(0).cpu().numpy()\n",
    "            pred_heatmaps = model.predict(video_transformed)\n",
    "            pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "            acc, _, _ = pose_pck_accuracy(\n",
    "                pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "            P = [P[i] + count_positive(acc[i]) for i in range(len(acc))]\n",
    "            TP = [TP[i] + ReLu(acc[i]) for i in range(len(acc))]\n",
    "            pred_keypoints = udp.decode(pred_heatmaps.squeeze())[0]\n",
    "            acc_udp, _, _ = keypoint_pck_accuracy(\n",
    "                pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "            P_udp = [P_udp[i] + count_positive(acc_udp[i])\n",
    "                        for i in range(len(acc_udp))]\n",
    "            TP_udp = [TP_udp[i] + ReLu(acc_udp[i]) for i in range(len(acc_udp))]\n",
    "            print(f\"video: {i} / {len(dataset)}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to json\n",
    "results = {\n",
    "    \"model_path\": model_path,\n",
    "    \"P\": P,\n",
    "    \"TP\": TP,\n",
    "    \"P_udp\": P_udp,\n",
    "    \"TP_udp\": TP_udp,\n",
    "    \"mean_acc\": get_mean_average_acc(TP, P),\n",
    "    \"mean_acc_udp\": get_mean_average_acc(TP_udp, P_udp),\n",
    "    \"acc_keypoints\": [TP[i]/P[i] if P[i]!=0 else 0 for i in range(len(TP))],\n",
    "    \"acc_keypoints_udp\": [TP_udp[i]/P_udp[i] if P_udp[i]!=0 else 0 for i in range(len(TP_udp))],\n",
    "}\n",
    "with open(\"./results/Single_Frame_ViT_Deconv_Untrained.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt21_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
