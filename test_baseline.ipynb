{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets.posetrack21 import PoseTrack21\n",
    "from utilities.utilities import keypoints_to_mask, accuracy, show_image, HiddenPrints, show_heatmaps, keypoints_to_label_flag\n",
    "from mmpose.evaluation import pose_pck_accuracy, keypoint_pck_accuracy\n",
    "from mmpose.codecs import UDPHeatmap\n",
    "from models.backbone.vit_with_fusion import FusionVit\n",
    "from models.head.deconv import DeconvHead\n",
    "from models.PoseEstimate import PoseEstimate\n",
    "from models.head import MaskHead, ResMaskHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ./checkpoints/Fusion_Deconv_02.pth at epoch 2380\n"
     ]
    }
   ],
   "source": [
    "# device = \"cpu\"\n",
    "device = \"cuda\"\n",
    "pretrained_path = \"./checkpoints/vitpose_base_coco_aic_mpii.pth\"\n",
    "encoder = FusionVit(pretrained_path=pretrained_path)\n",
    "neck = nn.Identity()\n",
    "head = DeconvHead(pretrained_path=pretrained_path)\n",
    "model = PoseEstimate(encoder=encoder, neck=neck, head=head)\n",
    "model.to(device)\n",
    "model_path = \"./checkpoints/Fusion_Deconv_02.pth\"\n",
    "# model_path = \"/home/junfeng/Documents/WorkSpace/SummerProject/COMP0073_2023_Junfeng/checkpoints/Fusion_Deconv_Best_02.pth\"\n",
    "model_dict = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(model_dict[\"model_state_dict\"])\n",
    "epoch = model_dict[\"epoch\"]\n",
    "print(f\"Loaded model from {model_path} at epoch {epoch}\")\n",
    "with HiddenPrints():\n",
    "    model.to(device)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_heatmaps(heatmaps):\n",
    "    \"\"\"\n",
    "    Normalizes heatmaps to the range [0, 1].\n",
    "\n",
    "    Parameters:\n",
    "    - heatmaps: torch.Tensor of shape (num_joints, height, width)\n",
    "                17 * 64 * 48 in your case.\n",
    "\n",
    "    Returns:\n",
    "    - normalized_heatmaps: torch.Tensor of shape (num_joints, height, width)\n",
    "    \"\"\"\n",
    "    num_joints, height, width = heatmaps.shape\n",
    "    normalized_heatmaps = torch.zeros_like(heatmaps, dtype=torch.float32)\n",
    "\n",
    "    for i in range(num_joints):\n",
    "        min_val = torch.min(heatmaps[i])\n",
    "        max_val = torch.max(heatmaps[i])\n",
    "\n",
    "        if max_val != min_val:\n",
    "            normalized_heatmaps[i] = (heatmaps[i] - min_val) / (max_val - min_val)\n",
    "\n",
    "    return normalized_heatmaps\n",
    "\n",
    "# Example usage\n",
    "heatmaps = torch.rand(17, 64, 48)  # Generating random heatmaps for 17 joints, 64x48 in size.\n",
    "normalized_heatmaps = normalize_heatmaps(heatmaps)\n",
    "\n",
    "# Now `normalized_heatmaps` contains the normalized values in the range [0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "dataset_root_dir = \"/home/junfeng/datasets/PoseTrack21\"\n",
    "dataset_train = PoseTrack21(\n",
    "    root_dir=dataset_root_dir,\n",
    "    set=\"train\",\n",
    ")\n",
    "\n",
    "dataset_test = PoseTrack21(\n",
    "    root_dir=dataset_root_dir,\n",
    "    set=\"test\",\n",
    ")\n",
    "\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7984534665334723, mean_avg_acc 0.7857575924075962\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 5000, mean_avg_acc_udp: 0.7934381041181088, mean_avg_acc 0.7790917232767276\r"
     ]
    }
   ],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 100)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 100)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "while count < 5000:\n",
    "    count += 1\n",
    "    i = np.random.randint(0, len(dataset))\n",
    "    video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 100)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 100)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 0)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 10)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model.denoise(video_transformed, pred_heatmaps, 200)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "mean_avg_acc_udp = 0\n",
    "mean_avg_acc = 0\n",
    "count = 0\n",
    "thr = 0.05\n",
    "for video, video_transformed, expanded_bbox, keypoints, keypoints_transformed, heatmaps, image_id, track_id in dataset.get_for_eval(1):\n",
    "    count += 1\n",
    "    mask = keypoints_to_mask(keypoints)\n",
    "    image = video[1]\n",
    "    decoder = UDPHeatmap(input_size=(192, 256), heatmap_size=(48, 64))\n",
    "    image_transformed = video_transformed[1]\n",
    "    video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        pred_heatmaps = model.predict(video_transformed)\n",
    "        pred_heatmaps = normalize_heatmaps(pred_heatmaps.squeeze()).unsqueeze(0)\n",
    "        pred_heatmaps = model(video_transformed, pred_heatmaps)\n",
    "        pred_heatmaps = pred_heatmaps.cpu().numpy()\n",
    "        _, avg_acc, _ = pose_pck_accuracy(\n",
    "            pred_heatmaps, heatmaps, mask, thr=thr)\n",
    "        mean_avg_acc += avg_acc\n",
    "        pred_heatmaps = pred_heatmaps.squeeze()\n",
    "        pred_keypoints = decoder.decode(pred_heatmaps)[0]\n",
    "        normalize = np.tile(np.array([[256, 192]]), (1, 1))\n",
    "        _, avg_acc_udp, _ = keypoint_pck_accuracy(\n",
    "            pred=pred_keypoints, gt=keypoints_transformed[:, :2].numpy(), mask=mask, thr=thr, norm_factor=normalize)\n",
    "        mean_avg_acc_udp += avg_acc_udp\n",
    "        print(\n",
    "            f\"count: {count}, mean_avg_acc_udp: {mean_avg_acc_udp / count}, mean_avg_acc {mean_avg_acc / count}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test\n",
    "loss_val = 0\n",
    "acc = 0\n",
    "count = 0\n",
    "i = np.random.randint(0, len(dataset))\n",
    "video, video_transformed, keypoints, keypoints_transformed, heatmaps = dataset[i]\n",
    "image = video[1]\n",
    "H, W, _ = image.shape\n",
    "decoder = UDPHeatmap(input_size=(W, H), heatmap_size=(48, 64))\n",
    "image_transformed = video_transformed[1]\n",
    "video_transformed = video_transformed.to(device).unsqueeze(0)\n",
    "show_image(image, keypoints)\n",
    "with torch.no_grad():\n",
    "    pred_heatmaps = model.predict(video_transformed)\n",
    "    show_image(image, heatmaps=pred_heatmaps.squeeze(0).cpu().numpy())\n",
    "    show_heatmaps(pred_heatmaps.squeeze(0).cpu().numpy())\n",
    "    pred_heatmaps = model.denoise(video_transformed, pred_heatmaps)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt21_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
